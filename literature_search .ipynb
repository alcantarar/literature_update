{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Pubmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Search Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "\n",
    "def search(query):\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='most recent', \n",
    "                            retmax='5000',\n",
    "                            retmode='xml', \n",
    "                            reldate = 7, #only within n days from now\n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "#search terms (can test string with Pubmed Advanced Search)\n",
    "search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Search and Save Paper Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "id_list = search_results['IdList']\n",
    "papers = fetch_details(id_list)\n",
    "print(\"\")\n",
    "titles = [0 for i in enumerate(papers['PubmedArticle'])]\n",
    "keywords = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "authors = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "links = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "journals = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "\n",
    "\n",
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    titles[i] = papers['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleTitle']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Print Paper Info in Github Markdown Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME ERROR\n"
     ]
    }
   ],
   "source": [
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "#     print(\"* [%s](https://www.ncbi.nlm.nih.gov/pubmed/%s)\" % (paper['MedlineCitation']['Article']['ArticleTitle'],paper['MedlineCitation']['PMID']))\n",
    "    links[i] = \"* [%s](https://www.ncbi.nlm.nih.gov/pubmed/%s)\" % (paper['MedlineCitation']['Article']['ArticleTitle'],paper['MedlineCitation']['PMID'])\n",
    "    auths = []\n",
    "    for auth in paper['MedlineCitation']['Article']['AuthorList']:\n",
    "        try:\n",
    "            auth_name = [auth['LastName'],auth['Initials']+',']\n",
    "            auth_name = ' '.join(auth_name)\n",
    "#             print(auth_name)\n",
    "            auths.append(auth_name)\n",
    "        except:\n",
    "            print('NAME ERROR')\n",
    "    authors[i] = ' '.join(auths)\n",
    "#     print('*%s*' % (paper['MedlineCitation']['Article']['Journal']['Title']) )\n",
    "    journals[i] = '*%s*' % (paper['MedlineCitation']['Article']['Journal']['Title']) \n",
    "    #store keywords \n",
    "#     print(\" - \") #uncomment to print keywords (1 of 3)\n",
    "    if paper['MedlineCitation']['KeywordList'] != []:\n",
    "        kwds = []\n",
    "        for kw in paper['MedlineCitation']['KeywordList'][0]:\n",
    "#             print(kw,'/') #uncomment to print keywords (2 of 3)\n",
    "            kwds.append(kw[:])         \n",
    "        keywords[i] = ' '.join(kwds)\n",
    "#     else:\n",
    "#         print(\"NO_KEYWORDS\") #uncomment to print keywords (3 of 3)\n",
    "#     print(\"<br>  \") #linebreak for github md \n",
    "    #end keywords test\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Skeletal muscles of hibernating black bears show minimal atrophy and phenotype shifting despite prolonged physical inactivity and starvation.](https://www.ncbi.nlm.nih.gov/pubmed/30998788)\n",
    "Miyazaki M,\n",
    "Shimozuru M,\n",
    "Tsubota T,\n",
    "*PloS one*\n",
    "<br>  \n",
    "\n",
    "* [Phase space methods for non-linear analysis of pedalling forces in cycling.](https://www.ncbi.nlm.nih.gov/pubmed/30998746)\n",
    "Kunert A,\n",
    "Ott M,\n",
    "Reuter T,\n",
    "Koska D,\n",
    "Maiwald C,\n",
    "*PloS one*\n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up title and keyword strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Papers:  155\n"
     ]
    }
   ],
   "source": [
    "print('Number of Papers: ',np.size(titles,0)) #number of papers. limited to 500. (retmax)\n",
    "#clean up titles\n",
    "import re\n",
    "titles = [t.lower() for t in titles] #same case\n",
    "titles = [t.replace('<sub>',' ').replace('</sub>','') for t in titles] #subscript\n",
    "titles = [t.replace('<i>',' ').replace('</i>','') for t in titles] #italics\n",
    "titles = [t.replace('[','').replace(']','') for t in titles] #remove brackets from html parser\n",
    "#clean up keywords\n",
    "keywords = [k.lower() for k in keywords] #same case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Top-performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('Models/keras_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"Models/keras_model.h5\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(\"\\nLoaded model from disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Associated Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Vectorizer\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load vectorizer and label encoder\n",
    "vect = pickle.load(open('Models/keras_Vectorizer.pkl','rb'))\n",
    "le = LabelEncoder()\n",
    "le.classes_   = np.load('Models/keras_LabelEncoder.npy')\n",
    "print('\\nLoaded Vectorizer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get titles for this week's literature update\n",
    "import pandas as pd\n",
    "papers_df = pd.DataFrame({'title': titles, 'keywords': keywords})\n",
    "#join keywords with titles\n",
    "papers_df['everything'] = papers_df['title'] + ' ' + papers_df['keywords']\n",
    "\n",
    "#vectorize \n",
    "titles_vec = vect.transform(papers_df['everything'])\n",
    "#OR if you don't want to use just the title:\n",
    "# titles_vec = vect.transform(papers_df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Topics For Each Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation of a freehand technique for cortica...</td>\n",
       "      <td>ORTHOPAEDICS/SPINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>short and long-term effects of bisphenol s (bp...</td>\n",
       "      <td>TISSUE/BIOMATERIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cryopreservation of tendon tissue using dimeth...</td>\n",
       "      <td>CELLULAR/SUBCELLULAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fluid supplementation accelerates epithelial r...</td>\n",
       "      <td>CELLULAR/SUBCELLULAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computational modeling of bone cells and their...</td>\n",
       "      <td>BONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 topic\n",
       "0  validation of a freehand technique for cortica...    ORTHOPAEDICS/SPINE\n",
       "1  short and long-term effects of bisphenol s (bp...    TISSUE/BIOMATERIAL\n",
       "2  cryopreservation of tendon tissue using dimeth...  CELLULAR/SUBCELLULAR\n",
       "3  fluid supplementation accelerates epithelial r...  CELLULAR/SUBCELLULAR\n",
       "4  computational modeling of bone cells and their...                  BONE"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_vec = model.predict(titles_vec)\n",
    "topics = [le.inverse_transform([np.argmax(top_val)])[0] for top_val in model.predict(titles_vec)]\n",
    "papers_df['topic'] = topics\n",
    "papers_df[['title','topic']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Paper Titles and Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store everything in DataFrame and sort by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  Literature_Updates/2019-4-20-litupdate.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>everything</th>\n",
       "      <th>topic</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation of a freehand technique for cortica...</td>\n",
       "      <td>cbt = cortical bone trajectory lis = less inva...</td>\n",
       "      <td>validation of a freehand technique for cortica...</td>\n",
       "      <td>ORTHOPAEDICS/SPINE</td>\n",
       "      <td>Tan Z, McLachlin S, Whyne C, Finkelstein J,</td>\n",
       "      <td>*Journal of neurosurgery. Spine*</td>\n",
       "      <td>* [Validation of a freehand technique for cort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>short and long-term effects of bisphenol s (bp...</td>\n",
       "      <td>breastfeeding developmental plasticity gestati...</td>\n",
       "      <td>short and long-term effects of bisphenol s (bp...</td>\n",
       "      <td>TISSUE/BIOMATERIAL</td>\n",
       "      <td>da Silva BS, Pietrobon CB, Bertasso IM, Lopes ...</td>\n",
       "      <td>*Environmental pollution (Barking, Essex : 1987)*</td>\n",
       "      <td>* [Short and long-term effects of bisphenol S ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cryopreservation of tendon tissue using dimeth...</td>\n",
       "      <td></td>\n",
       "      <td>cryopreservation of tendon tissue using dimeth...</td>\n",
       "      <td>CELLULAR/SUBCELLULAR</td>\n",
       "      <td>Hochstrat E, Müller M, Frank A, Michel P, Hans...</td>\n",
       "      <td>*PloS one*</td>\n",
       "      <td>* [Cryopreservation of tendon tissue using dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fluid supplementation accelerates epithelial r...</td>\n",
       "      <td></td>\n",
       "      <td>fluid supplementation accelerates epithelial r...</td>\n",
       "      <td>CELLULAR/SUBCELLULAR</td>\n",
       "      <td>Burgueño JF, Lang JK, Santander AM, Fernández ...</td>\n",
       "      <td>*PloS one*</td>\n",
       "      <td>* [Fluid supplementation accelerates epithelia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computational modeling of bone cells and their...</td>\n",
       "      <td></td>\n",
       "      <td>computational modeling of bone cells and their...</td>\n",
       "      <td>BONE</td>\n",
       "      <td>Wang L, Dong J, Xian CJ,</td>\n",
       "      <td>*Critical reviews in eukaryotic gene expression*</td>\n",
       "      <td>* [Computational Modeling of Bone Cells and Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  validation of a freehand technique for cortica...   \n",
       "1  short and long-term effects of bisphenol s (bp...   \n",
       "2  cryopreservation of tendon tissue using dimeth...   \n",
       "3  fluid supplementation accelerates epithelial r...   \n",
       "4  computational modeling of bone cells and their...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  cbt = cortical bone trajectory lis = less inva...   \n",
       "1  breastfeeding developmental plasticity gestati...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                          everything                 topic  \\\n",
       "0  validation of a freehand technique for cortica...    ORTHOPAEDICS/SPINE   \n",
       "1  short and long-term effects of bisphenol s (bp...    TISSUE/BIOMATERIAL   \n",
       "2  cryopreservation of tendon tissue using dimeth...  CELLULAR/SUBCELLULAR   \n",
       "3  fluid supplementation accelerates epithelial r...  CELLULAR/SUBCELLULAR   \n",
       "4  computational modeling of bone cells and their...                  BONE   \n",
       "\n",
       "                                             authors  \\\n",
       "0        Tan Z, McLachlin S, Whyne C, Finkelstein J,   \n",
       "1  da Silva BS, Pietrobon CB, Bertasso IM, Lopes ...   \n",
       "2  Hochstrat E, Müller M, Frank A, Michel P, Hans...   \n",
       "3  Burgueño JF, Lang JK, Santander AM, Fernández ...   \n",
       "4                           Wang L, Dong J, Xian CJ,   \n",
       "\n",
       "                                             journal  \\\n",
       "0                   *Journal of neurosurgery. Spine*   \n",
       "1  *Environmental pollution (Barking, Essex : 1987)*   \n",
       "2                                         *PloS one*   \n",
       "3                                         *PloS one*   \n",
       "4   *Critical reviews in eukaryotic gene expression*   \n",
       "\n",
       "                                               links  \n",
       "0  * [Validation of a freehand technique for cort...  \n",
       "1  * [Short and long-term effects of bisphenol S ...  \n",
       "2  * [Cryopreservation of tendon tissue using dim...  \n",
       "3  * [Fluid supplementation accelerates epithelia...  \n",
       "4  * [Computational Modeling of Bone Cells and Th...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add info for github markdown format\n",
    "papers_df['authors'] = authors\n",
    "papers_df['journal'] = journals\n",
    "papers_df['links'] = links\n",
    "#generate filename\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.csv']\n",
    "fname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.md']\n",
    "mdname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate']\n",
    "urlname = '-'.join(strings)\n",
    "\n",
    "print('Filename: ',fname)\n",
    "\n",
    "# papers_df = papers_df.sort_values(by = ['topic'])\n",
    "# papers_df = papers_df.reset_index(drop = True)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header = ['title','topic']\n",
    "# papers_df.sort_values('topic').to_csv(fname, index = False, columns = header)\n",
    "# print('\\nLiterature Update Exported as .csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile papers grouped by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Literature Update Exported as Markdown\n"
     ]
    }
   ],
   "source": [
    "#header for alcantarar.github.io literature update site:\n",
    "print('---',file=open(mdname,\"w\"))\n",
    "print('title: Biomechanics Literature Update',file=open(mdname,\"a\"))\n",
    "print('collection: literature',file=open(mdname,\"a\"))\n",
    "print('permalink: /literature/'+urlname,file=open(mdname,\"a\"))\n",
    "print('excerpt: <br>',file=open(mdname,\"a\"))\n",
    "print('---',file=open(mdname,\"a\"))\n",
    "\n",
    "\n",
    "topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n",
    "# print('# Literature Update: ',str(now.year)+'-'+str(now.month)+'-'+str(now.day),'  ', file = open(mdname,'w'))\n",
    "print('### Created by: [Ryan Alcantara](https://twitter.com/Ryan_Alcantara_) & [Gary Bruening](https://twitter.com/garebearbru) - University of Colorado Boulder', file=open(mdname, \"a\"))\n",
    "print('### Table Of Contents: ', file=open(mdname, \"a\"))\n",
    "for topic in topic_list:\n",
    "    print('['+topic+']'+'(#'+str.lower(topic).replace('/','')+')  ', file=open(mdname, \"a\"))\n",
    "print('', file=open(mdname,\"a\"))\n",
    "for topic in topic_list:\n",
    "    print('----', file=open(mdname, \"a\"))\n",
    "    print('#',topic, file=open(mdname, \"a\"))\n",
    "    print('----', file=open(mdname, \"a\"))\n",
    "    print('', file=open(mdname, \"a\"))\n",
    "    print('[Back to top](#table-of-contents)', file=open(mdname, \"a\"))\n",
    "    print('', file=open(mdname, \"a\"))\n",
    "    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop = True))\n",
    "    for i,paper in enumerate(papers_subset['links']):\n",
    "        print(paper, file=open(mdname, \"a\"))\n",
    "        print(papers_subset['authors'][i], file=open(mdname, \"a\"))\n",
    "        print(papers_subset['journal'][i]+'.  ', file=open(mdname, \"a\"))\n",
    "#         print('<br>  ', file=open(\"output.md\", \"a\"))\n",
    "        print('', file=open(mdname, \"a\"))\n",
    "    \n",
    "print('Literature Update Exported as Markdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
