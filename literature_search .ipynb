{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Pubmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Search Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "\n",
    "def search(query):\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='most recent', \n",
    "                            retmax='5000',\n",
    "                            retmode='xml', \n",
    "                            reldate = 7, #only within n days from now\n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "#search terms (can test string with Pubmed Advanced Search)\n",
    "search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Search and Save Paper Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "122 Papers found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "id_list = search_results['IdList']\n",
    "papers = fetch_details(id_list)\n",
    "print(\"\")\n",
    "titles = [0 for i in enumerate(papers['PubmedArticle'])]\n",
    "keywords = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "authors = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "links = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "journals = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "\n",
    "\n",
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    titles[i] = papers['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleTitle']\n",
    "print(np.size(titles),'Papers found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull information from PubMed Results\n",
    "#### Format title, journal, authors in markdown friendly manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    links[i] = \"* [%s](https://www.ncbi.nlm.nih.gov/pubmed/%s)\" % (paper['MedlineCitation']['Article']['ArticleTitle'],paper['MedlineCitation']['PMID'])\n",
    "    auths = []\n",
    "    for auth in paper['MedlineCitation']['Article']['AuthorList']:\n",
    "        try:\n",
    "            auth_name = [auth['LastName'],auth['Initials']+',']\n",
    "            auth_name = ' '.join(auth_name)\n",
    "            auths.append(auth_name)\n",
    "        except:\n",
    "            print(paper['MedlineCitation']['Article']['ArticleTitle'],'- NAME ERROR')\n",
    "    authors[i] = ' '.join(auths)\n",
    "    journals[i] = '*%s*' % (paper['MedlineCitation']['Article']['Journal']['Title']) \n",
    "    #store keywords \n",
    "    if paper['MedlineCitation']['KeywordList'] != []:\n",
    "        kwds = []\n",
    "        for kw in paper['MedlineCitation']['KeywordList'][0]:\n",
    "            kwds.append(kw[:])         \n",
    "        keywords[i] = ' '.join(kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Skeletal muscles of hibernating black bears show minimal atrophy and phenotype shifting despite prolonged physical inactivity and starvation.](https://www.ncbi.nlm.nih.gov/pubmed/30998788)\n",
    "Miyazaki M,\n",
    "Shimozuru M,\n",
    "Tsubota T,\n",
    "*PloS one*\n",
    "<br>  \n",
    "\n",
    "* [Phase space methods for non-linear analysis of pedalling forces in cycling.](https://www.ncbi.nlm.nih.gov/pubmed/30998746)\n",
    "Kunert A,\n",
    "Ott M,\n",
    "Reuter T,\n",
    "Koska D,\n",
    "Maiwald C,\n",
    "*PloS one*\n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up title and keyword strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Papers:  122\n"
     ]
    }
   ],
   "source": [
    "print('Number of Papers: ',np.size(titles,0)) #number of papers. limited to 500. (retmax)\n",
    "#clean up titles\n",
    "import re\n",
    "titles = [t.lower() for t in titles] #same case\n",
    "titles = [t.replace('<sub>',' ').replace('</sub>','') for t in titles] #subscript\n",
    "titles = [t.replace('<i>',' ').replace('</i>','') for t in titles] #italics\n",
    "titles = [t.replace('[','').replace(']','') for t in titles] #remove brackets from html parser\n",
    "#clean up keywords\n",
    "keywords = [k.lower() for k in keywords] #same case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Top-performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('Models/keras_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"Models/keras_model.h5\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(\"\\nLoaded model from disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Associated Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load vectorizer and label encoder\n",
    "vect = pickle.load(open('Models/keras_Vectorizer.pkl','rb'))\n",
    "le = LabelEncoder()\n",
    "le.classes_   = np.load('Models/keras_LabelEncoder.npy')\n",
    "print('\\nLoaded Vectorizer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get titles for this week's literature update\n",
    "import pandas as pd\n",
    "papers_df = pd.DataFrame({'title': titles, 'keywords': keywords})\n",
    "#join keywords with titles\n",
    "papers_df['everything'] = papers_df['title'] + ' ' + papers_df['keywords']\n",
    "\n",
    "#vectorize \n",
    "titles_vec = vect.transform(papers_df['everything'])\n",
    "#OR if you don't want to use just the title:\n",
    "# titles_vec = vect.transform(papers_df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Topics For Each Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_vec = model.predict(titles_vec)\n",
    "topics = [le.inverse_transform([np.argmax(top_val)])[0] for top_val in model.predict(titles_vec)]\n",
    "papers_df['topic'] = topics\n",
    "papers_df[['title','topic']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Paper Titles and Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store everything in DataFrame and sort by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add info for github markdown format\n",
    "papers_df['authors'] = authors\n",
    "papers_df['journal'] = journals\n",
    "papers_df['links'] = links\n",
    "#generate filename\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.csv']\n",
    "fname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.md']\n",
    "mdname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate']\n",
    "urlname = '-'.join(strings)\n",
    "\n",
    "print('Filename: ',fname)\n",
    "\n",
    "# papers_df = papers_df.sort_values(by = ['topic'])\n",
    "# papers_df = papers_df.reset_index(drop = True)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header = ['title','topic']\n",
    "# papers_df.sort_values('topic').to_csv(fname, index = False, columns = header)\n",
    "# print('\\nLiterature Update Exported as .csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile papers grouped by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_file = open(mdname, 'w', encoding = 'utf-8')\n",
    "md_file.write('---\\n')\n",
    "md_file.write('title: Biomechanics Literature Update\\n')\n",
    "md_file.write('collection: literature\\n')\n",
    "md_file.write('permalink: /literature/%s\\n' % urlname)\n",
    "md_file.write('excerpt: <br>\\n')\n",
    "md_file.write('---\\n')\n",
    "\n",
    "\n",
    "#tidy up topic strings\n",
    "topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n",
    "ss = [s for s in topic_list if 'UNIQUE' in s]\n",
    "for i,t in enumerate(topic_list):\n",
    "    if 'UNIQUE' in t:  \n",
    "        topic_list[i] = 'UNIQUE TOPIC'\n",
    "    if 'IMPACT' in t:\n",
    "        topic_list[i] = 'TRAUMA/IMPACT'\n",
    "\n",
    "md_file.write('### Created by: [Ryan Alcantara](https://twitter.com/Ryan_Alcantara_) & [Gary Bruening](https://twitter.com/garebearbru) - University of Colorado Boulder\\n')\n",
    "md_file.write('### Table Of Contents: \\n')\n",
    "for topic in topic_list:\n",
    "    md_file.write('[%s](#%s)  \\n' % (topic, str.lower(topic).replace('/','').replace(' ','')))\n",
    "md_file.write('\\n')\n",
    "for topic in topic_list:\n",
    "    md_file.write('----\\n')\n",
    "    md_file.write('# %s\\n' % topic)\n",
    "    md_file.write('----\\n')\n",
    "    md_file.write('\\n')\n",
    "    md_file.write('[Back to top](#table-of-contents)')\n",
    "    md_file.write('\\n')\n",
    "    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop = True))\n",
    "    for i,paper in enumerate(papers_subset['links']):\n",
    "        md_file.write('%s\\n' % paper)\n",
    "        md_file.write('%s\\n' % papers_subset['authors'][i])\n",
    "        md_file.write('%s.  \\n' % papers_subset['journal'][i])\n",
    "        md_file.write('\\n')\n",
    "\n",
    "md_file.close()\n",
    "print('Literature Update Exported as Markdown')\n",
    "print('Location:',mdname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
