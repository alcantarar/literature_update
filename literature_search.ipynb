{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Pubmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Search Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "\n",
    "def search(query):\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='most recent', \n",
    "                            retmax='5000',\n",
    "                            retmode='xml', \n",
    "                            datetype = 'pdat',\n",
    "                            reldate = 7, #only within n days from now\n",
    "#                             mindate = '2019/03/25',\n",
    "#                             maxdate = '2019/03/27', #for searching date range\n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "#search terms (can test string with Pubmed Advanced Search)\n",
    "search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')\n",
    "#((biomech*) OR locomot*)\n",
    "# search_results = search('((biomech*) OR locomot*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Search and Save Paper Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "353 Papers found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "id_list = search_results['IdList']\n",
    "papers = fetch_details(id_list)\n",
    "print(\"\")\n",
    "titles = [0 for i in enumerate(papers['PubmedArticle'])]\n",
    "keywords = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "authors = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "links = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "journals = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "\n",
    "\n",
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    titles[i] = papers['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleTitle']\n",
    "print(np.size(titles),'Papers found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull information from PubMed Results\n",
    "#### Format title, journal, authors in markdown friendly manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors of Healing Ligament Size and Magnetic Resonance Signal Intensity at 6 Months After Bridge-Enhanced Anterior Cruciate Ligament Repair. has an issue with an author name\n"
     ]
    }
   ],
   "source": [
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    links[i] = \"* [%s](https://www.ncbi.nlm.nih.gov/pubmed/%s)\" % (paper['MedlineCitation']['Article']['ArticleTitle'],paper['MedlineCitation']['PMID'])\n",
    "    auths = []\n",
    "    try:\n",
    "        for auth in paper['MedlineCitation']['Article']['AuthorList']:\n",
    "            try:\n",
    "                auth_name = [auth['LastName'],auth['Initials']+',']\n",
    "                auth_name = ' '.join(auth_name)\n",
    "                auths.append(auth_name)\n",
    "            except:\n",
    "                print(paper['MedlineCitation']['Article']['ArticleTitle'],'has an issue with an author name')\n",
    "    except:\n",
    "        auths.append('AUTHOR NAMES ERROR')\n",
    "        print(paper['MedlineCitation']['Article']['ArticleTitle'],'has no author list?')\n",
    "    authors[i] = ' '.join(auths)\n",
    "    journals[i] = '*%s*' % (paper['MedlineCitation']['Article']['Journal']['Title']) \n",
    "    #store keywords \n",
    "    if paper['MedlineCitation']['KeywordList'] != []:\n",
    "        kwds = []\n",
    "        for kw in paper['MedlineCitation']['KeywordList'][0]:\n",
    "            kwds.append(kw[:])         \n",
    "        keywords[i] = ' '.join(kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up title and keyword strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "titles = [t.lower() for t in titles] #same case\n",
    "titles = [t.replace('<sub>',' ').replace('</sub>','') for t in titles] #subscript\n",
    "titles = [t.replace('<i>',' ').replace('</i>','') for t in titles] #italics\n",
    "titles = [t.replace('[','').replace(']','') for t in titles] #remove brackets from html parser\n",
    "#clean up keywords\n",
    "keywords = [k.lower() for k in keywords] #same case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Top-performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import model_from_json\n",
    "# # load json and create model\n",
    "# json_file = open('Models/keras_model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# model.load_weights(\"Models/keras_model.h5\")\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# print(\"\\nLoaded model from disk\")\n",
    " \n",
    "#OR NEW WAY:\n",
    "from keras.models import load_model\n",
    "model = load_model('Models/Keras_model/model_DNN.h5')\n",
    "print('\\nLoaded model from disk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Associated Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib #pickle.load throws warning.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load vectorizer and label encoder\n",
    "vect = joblib.load(open('Models/Keras_model/Vectorizer_tdif.pkl','rb'))\n",
    "# vect = joblib.load(open('Models/Keras_model/Vectorizer_count.pkl','rb'))\n",
    "le = LabelEncoder()\n",
    "le.classes_   = np.load('Models/Keras_model/LabelEncoder.npy')\n",
    "print('\\nLoaded Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get titles for this week's literature update\n",
    "import pandas as pd\n",
    "papers_df = pd.DataFrame({'title': titles, 'keywords': keywords})\n",
    "#join keywords with titles\n",
    "# papers_df['everything'] = papers_df['title'] + ' ' + papers_df['keywords']\n",
    "#OR just titles\n",
    "papers_df['everything'] = papers_df['title']\n",
    "#vectorize \n",
    "titles_vec = vect.transform(papers_df['everything'])\n",
    "#OR if you don't want to use just the title:\n",
    "# titles_vec = vect.transform(papers_df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Topics For Each Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_vec = model.predict(titles_vec)\n",
    "topics = [le.inverse_transform([np.argmax(top_val)])[0] for top_val in model.predict(titles_vec)]\n",
    "papers_df['topic'] = topics\n",
    "pd.set_option('display.max_colwidth', -1) #don't cut cell short in dataframe\n",
    "papers_df[['title','topic']].sample(5)\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Paper Titles and Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store everything in DataFrame and sort by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  Literature_Updates/2019-5-7-litupdate.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>everything</th>\n",
       "      <th>topic</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a biomechanical analysis of lateral interbody ...</td>\n",
       "      <td>asd adjacent segment disease lateral lumbar in...</td>\n",
       "      <td>a biomechanical analysis of lateral interbody ...</td>\n",
       "      <td>ORTHOPAEDICS/SPINE</td>\n",
       "      <td>McMains MC, Jain N, Malik AT, Cerier E, Litsky...</td>\n",
       "      <td>*World neurosurgery*</td>\n",
       "      <td>* [A Biomechanical Analysis of Lateral Interbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mcgregor's slope and slope of line of sight: t...</td>\n",
       "      <td>cbva mcgregor's slope sls biomechanics cervica...</td>\n",
       "      <td>mcgregor's slope and slope of line of sight: t...</td>\n",
       "      <td>ORTHOPAEDICS/SPINE</td>\n",
       "      <td>Moses MJ, Tishelman JC, Zhou PL, Moon JY, Beau...</td>\n",
       "      <td>*The spine journal : official journal of the N...</td>\n",
       "      <td>* [McGregor's Slope and Slope of Line of Sight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>involvement of the gabaa receptor α subunit in...</td>\n",
       "      <td>efx-binding mode gaba(a) receptors anxiolysis ...</td>\n",
       "      <td>involvement of the gabaa receptor α subunit in...</td>\n",
       "      <td>NEURAL</td>\n",
       "      <td>Mattei C, Taly A, Soualah Z, Saulais O, Henrio...</td>\n",
       "      <td>*Pharmacological research*</td>\n",
       "      <td>* [Involvement of the GABAA receptor α subunit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quantifying vocal fold wound-healing biomechan...</td>\n",
       "      <td>voice biomechanics injury microindentation voc...</td>\n",
       "      <td>quantifying vocal fold wound-healing biomechan...</td>\n",
       "      <td>TISSUE/BIOMATERIAL</td>\n",
       "      <td>Dion GR, Guda T, Mukudai S, Bing R, Lavoie JF,...</td>\n",
       "      <td>*The Laryngoscope*</td>\n",
       "      <td>* [Quantifying vocal fold wound-healing biomec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biomechanics of lasik flap and smile cap: a pr...</td>\n",
       "      <td></td>\n",
       "      <td>biomechanics of lasik flap and smile cap: a pr...</td>\n",
       "      <td>DENTAL/ORAL/FACIAL</td>\n",
       "      <td>Khamar P, Shetty R, Vaishnav R, Francis M, Nui...</td>\n",
       "      <td>*Journal of refractive surgery (Thorofare, N.J...</td>\n",
       "      <td>* [Biomechanics of LASIK Flap and SMILE Cap: A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  a biomechanical analysis of lateral interbody ...   \n",
       "1  mcgregor's slope and slope of line of sight: t...   \n",
       "2  involvement of the gabaa receptor α subunit in...   \n",
       "3  quantifying vocal fold wound-healing biomechan...   \n",
       "4  biomechanics of lasik flap and smile cap: a pr...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  asd adjacent segment disease lateral lumbar in...   \n",
       "1  cbva mcgregor's slope sls biomechanics cervica...   \n",
       "2  efx-binding mode gaba(a) receptors anxiolysis ...   \n",
       "3  voice biomechanics injury microindentation voc...   \n",
       "4                                                      \n",
       "\n",
       "                                          everything               topic  \\\n",
       "0  a biomechanical analysis of lateral interbody ...  ORTHOPAEDICS/SPINE   \n",
       "1  mcgregor's slope and slope of line of sight: t...  ORTHOPAEDICS/SPINE   \n",
       "2  involvement of the gabaa receptor α subunit in...              NEURAL   \n",
       "3  quantifying vocal fold wound-healing biomechan...  TISSUE/BIOMATERIAL   \n",
       "4  biomechanics of lasik flap and smile cap: a pr...  DENTAL/ORAL/FACIAL   \n",
       "\n",
       "                                             authors  \\\n",
       "0  McMains MC, Jain N, Malik AT, Cerier E, Litsky...   \n",
       "1  Moses MJ, Tishelman JC, Zhou PL, Moon JY, Beau...   \n",
       "2  Mattei C, Taly A, Soualah Z, Saulais O, Henrio...   \n",
       "3  Dion GR, Guda T, Mukudai S, Bing R, Lavoie JF,...   \n",
       "4  Khamar P, Shetty R, Vaishnav R, Francis M, Nui...   \n",
       "\n",
       "                                             journal  \\\n",
       "0                               *World neurosurgery*   \n",
       "1  *The spine journal : official journal of the N...   \n",
       "2                         *Pharmacological research*   \n",
       "3                                 *The Laryngoscope*   \n",
       "4  *Journal of refractive surgery (Thorofare, N.J...   \n",
       "\n",
       "                                               links  \n",
       "0  * [A Biomechanical Analysis of Lateral Interbo...  \n",
       "1  * [McGregor's Slope and Slope of Line of Sight...  \n",
       "2  * [Involvement of the GABAA receptor α subunit...  \n",
       "3  * [Quantifying vocal fold wound-healing biomec...  \n",
       "4  * [Biomechanics of LASIK Flap and SMILE Cap: A...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add info for github markdown format\n",
    "papers_df['authors'] = authors\n",
    "papers_df['journal'] = journals\n",
    "papers_df['links'] = links\n",
    "#generate filename\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.csv']\n",
    "fname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.md']\n",
    "mdname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate']\n",
    "urlname = '-'.join(strings)\n",
    "\n",
    "print('Filename: ',fname)\n",
    "\n",
    "# papers_df = papers_df.sort_values(by = ['topic'])\n",
    "# papers_df = papers_df.reset_index(drop = True)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Literature Update Exported as .csv\n"
     ]
    }
   ],
   "source": [
    "papers_df.sort_values('topic').to_csv(fname, index = False)\n",
    "print('\\nLiterature Update Exported as .csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile papers grouped by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Literature Update Exported as Markdown\n",
      "Location: Literature_Updates/2019-5-7-litupdate.md\n"
     ]
    }
   ],
   "source": [
    "md_file = open(mdname, 'w', encoding = 'utf-8')\n",
    "md_file.write('---\\n')\n",
    "md_file.write('title: Biomechanics Literature Update\\n')\n",
    "md_file.write('collection: literature\\n')\n",
    "md_file.write('permalink: /literature/%s\\n' % urlname)\n",
    "md_file.write('excerpt: <br>\\n')\n",
    "md_file.write('toc: true\\n')\n",
    "md_file.write('toc_sticky: true\\n')\n",
    "md_file.write('toc_label: Topics\\n')\n",
    "md_file.write('---\\n')\n",
    "\n",
    "#tidy up topic strings\n",
    "topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n",
    "ss = [s for s in topic_list if 'UNIQUE' in s]\n",
    "for i,t in enumerate(topic_list):\n",
    "    if 'UNIQUE' in t:  \n",
    "        topic_list[i] = 'UNIQUE TOPIC'\n",
    "    if 'IMPACT' in t:\n",
    "        topic_list[i] = 'TRAUMA/IMPACT'\n",
    "\n",
    "md_file.write('### Created by: [Ryan Alcantara](https://twitter.com/Ryan_Alcantara_) & [Gary Bruening](https://twitter.com/garebearbru) - University of Colorado Boulder\\n\\n')\n",
    "# md_file.write('### Table Of Contents: \\n')\n",
    "# for topic in topic_list:\n",
    "#     md_file.write('[%s](#%s)  \\n' % (topic, str.lower(topic).replace('/','').replace(' ','')))\n",
    "# md_file.write('\\n')\n",
    "for topic in topic_list:\n",
    "    md_file.write('----\\n')\n",
    "    md_file.write('# %s\\n' % topic)\n",
    "    md_file.write('----\\n')\n",
    "    md_file.write('\\n')\n",
    "    md_file.write('[Back to top](#created-by-ryan-alcantara--gary-bruening---university-of-colorado-boulder)')\n",
    "    md_file.write('\\n')\n",
    "    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop = True))\n",
    "    for i,paper in enumerate(papers_subset['links']):\n",
    "        md_file.write('%s\\n' % paper)\n",
    "        md_file.write('%s\\n' % papers_subset['authors'][i])\n",
    "        md_file.write('%s.  \\n' % papers_subset['journal'][i])\n",
    "        md_file.write('\\n')\n",
    "\n",
    "md_file.close()\n",
    "print('Literature Update Exported as Markdown')\n",
    "print('Location:',mdname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
