{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Pubmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Search Criteria"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "\n",
    "def search(query):\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='most recent', \n",
    "                            retmax='5000',\n",
    "                            retmode='xml', \n",
    "                            datetype = 'pdat',\n",
    "                            reldate = 7, #only within n days from now\n",
    "#                             mindate = '2019/03/25',\n",
    "#                             maxdate = '2019/03/27', #for searching date range\n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "#search terms (can test string with Pubmed Advanced Search)\n",
    "search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')\n",
    "#((biomech*) OR locomot*)\n",
    "# search_results = search('((biomech*) OR locomot*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Search and Save Paper Titles"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",

      "174 Papers found\n"
     ]
    }
   ],
   "source": [
    "def fetch_details(id_list):\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = 'your.email@example.com'\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "id_list = search_results['IdList']\n",
    "papers = fetch_details(id_list)\n",
    "print(\"\")\n",
    "titles = [0 for i in enumerate(papers['PubmedArticle'])]\n",
    "keywords = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "authors = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "links = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "journals = ['' for i in enumerate(papers['PubmedArticle'])]\n",
    "\n",
    "\n",
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    titles[i] = papers['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleTitle']\n",
    "print(np.size(titles),'Papers found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull information from PubMed Results\n",
    "#### Format title, journal, authors in markdown friendly manner"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Hyperbaric Oxygen Therapy After Acute Thoracic Spinal Cord Injury: Improvement of Locomotor Recovery in Rats: Erratum. has no author list?\n"
     ]
    }
   ],
   "source": [
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    if paper['MedlineCitation']['Article']['ArticleTitle'][0] is '[':\n",
    "        links[i] = \"* [%s](https://www.ncbi.nlm.nih.gov/pubmed/%s)\" % (paper['MedlineCitation']['Article']['ArticleTitle'][1:-1],paper['MedlineCitation']['PMID'])\n",
    "    else:\n",
    "        links[i] = \"* [%s](https://www.ncbi.nlm.nih.gov/pubmed/%s)\" % (paper['MedlineCitation']['Article']['ArticleTitle'],paper['MedlineCitation']['PMID'])\n",
    "        \n",
    "    auths = []\n",
    "    try:\n",
    "        for auth in paper['MedlineCitation']['Article']['AuthorList']:\n",
    "            try:\n",
    "                auth_name = [auth['LastName'],auth['Initials']+',']\n",
    "                auth_name = ' '.join(auth_name)\n",
    "                auths.append(auth_name)\n",
    "            except:\n",
    "                print(paper['MedlineCitation']['Article']['ArticleTitle'],'has an issue with an author name')\n",
    "    except:\n",
    "        auths.append('AUTHOR NAMES ERROR')\n",
    "        print(paper['MedlineCitation']['Article']['ArticleTitle'],'has no author list?')\n",
    "    authors[i] = ' '.join(auths)\n",
    "    journals[i] = '*%s*' % (paper['MedlineCitation']['Article']['Journal']['Title']) \n",
    "    #store keywords \n",
    "    if paper['MedlineCitation']['KeywordList'] != []:\n",
    "        kwds = []\n",
    "        for kw in paper['MedlineCitation']['KeywordList'][0]:\n",
    "            kwds.append(kw[:])         \n",
    "        keywords[i] = ' '.join(kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up title and keyword strings"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "titles = [t.lower() for t in titles] #same case\n",
    "titles = [t.replace('<sub>',' ').replace('</sub>','') for t in titles] #subscript\n",
    "titles = [t.replace('<i>',' ').replace('</i>','') for t in titles] #italics\n",
    "titles = [t.replace('[','').replace(']','') for t in titles] #remove brackets from html parser\n",
    "#clean up keywords\n",
    "keywords = [k.lower() for k in keywords] #same case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Top-performing Model"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import model_from_json\n",
    "# # load json and create model\n",
    "# json_file = open('Models/keras_model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# model.load_weights(\"Models/keras_model.h5\")\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# print(\"\\nLoaded model from disk\")\n",
    " \n",
    "#OR NEW WAY:\n",
    "from keras.models import load_model\n",
    "model = load_model('Models/Keras_model/model_DNN.h5')\n",
    "print('\\nLoaded model from disk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Associated Vectorizer"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Vectorizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib #pickle.load throws warning.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load vectorizer and label encoder\n",
    "vect = joblib.load(open('Models/Keras_model/Vectorizer_tdif.pkl','rb'))\n",
    "# vect = joblib.load(open('Models/Keras_model/Vectorizer_count.pkl','rb'))\n",
    "le = LabelEncoder()\n",
    "le.classes_   = np.load('Models/Keras_model/LabelEncoder.npy')\n",
    "print('\\nLoaded Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Strings"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get titles for this week's literature update\n",
    "import pandas as pd\n",
    "papers_df = pd.DataFrame({'title': titles, 'keywords': keywords})\n",
    "#join keywords with titles\n",
    "# papers_df['everything'] = papers_df['title'] + ' ' + papers_df['keywords']\n",
    "#OR just titles\n",
    "papers_df['everything'] = papers_df['title']\n",
    "#vectorize \n",
    "titles_vec = vect.transform(papers_df['everything'])\n",
    "#OR if you don't want to use just the title:\n",
    "# titles_vec = vect.transform(papers_df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Topics For Each Paper"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_vec = model.predict(titles_vec)\n",
    "\n",
    "topics = []\n",
    "pred_val = []\n",
    "title_temp = []\n",
    "indx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, top_val in enumerate(prediction_vec):\n",
    "    pred_val = np.max(top_val)\n",
    "    if pred_val > 0*np.sort(top_val)[-2]:\n",
    "        indx.append(k)\n",
    "        topics.append(le.inverse_transform([np.argmax(top_val)])[0])\n",
    "        title_temp.append(papers_df['title'][k])\n",
    "    else:\n",
    "        indx.append(k)\n",
    "        topics.append('unknown')\n",
    "        title_temp.append(papers_df['title'][k])\n",
    "# topics = [le.inverse_transform([np.argmax(top_val)])[0] for top_val in prediction_vec]\n",
    "# papers_df['topic'] = topics\n",
    "papers_df = pd.DataFrame(data = {'title': title_temp,\n",
    "                                  'topic': topics})\n",
    "pd.set_option('display.max_colwidth', -1) #don't cut cell short in dataframe\n",
    "papers_df[['title','topic']].sample(5)\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# topval = prediction_vec[5,:]\n",
    "# print(papers_df['title'][5])\n",
    "# print(le.inverse_transform([np.argmax(top_val)])[0])\n",
    "# print(np.sort(top_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Paper Titles and Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store everything in DataFrame and sort by Topic"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Filename:  Literature_Updates/2019-5-5-litupdate.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radiological, functional, and anatomical outco...</td>\n",
       "      <td>JOINT/CARTILAGE</td>\n",
       "      <td>Habib MK, Khan ZA,</td>\n",
       "      <td>*SICOT-J*</td>\n",
       "      <td>* [Radiological, functional, and anatomical ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application of individualized 3d-printed artif...</td>\n",
       "      <td>ORTHOPAEDICS/SPINE</td>\n",
       "      <td>Yang X, Wan W, Gong H, Xiao J,</td>\n",
       "      <td>*Turkish neurosurgery*</td>\n",
       "      <td>* [Application of Individualized 3D-Printed Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do stabilization exercises increase the effect...</td>\n",
       "      <td>ORTHOPAEDICS/SPINE</td>\n",
       "      <td>Cetin H, Kose N, Turkmen C, Dulger E, Bilgin S...</td>\n",
       "      <td>*Turkish neurosurgery*</td>\n",
       "      <td>* [Do Stabilization Exercises Increase the Eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pigment epithelium-derived factor promotes axo...</td>\n",
       "      <td>NEURAL</td>\n",
       "      <td>Stevens AR, Ahmed U, Vigneswara V, Ahmed Z,</td>\n",
       "      <td>*Molecular neurobiology*</td>\n",
       "      <td>* [Pigment Epithelium-Derived Factor Promotes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the role of the medial plate for pauwels type ...</td>\n",
       "      <td>ORTHOPAEDICS/SURGERY</td>\n",
       "      <td>Giordano V, Alves DD, Paes RP, Amaral AB, Gior...</td>\n",
       "      <td>*Journal of experimental orthopaedics*</td>\n",
       "      <td>* [The role of the medial plate for Pauwels ty...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 topic  \\\n",
       "0  radiological, functional, and anatomical outco...       JOINT/CARTILAGE   \n",
       "1  application of individualized 3d-printed artif...    ORTHOPAEDICS/SPINE   \n",
       "2  do stabilization exercises increase the effect...    ORTHOPAEDICS/SPINE   \n",
       "3  pigment epithelium-derived factor promotes axo...                NEURAL   \n",
       "4  the role of the medial plate for pauwels type ...  ORTHOPAEDICS/SURGERY   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                 Habib MK, Khan ZA,   \n",
       "1                     Yang X, Wan W, Gong H, Xiao J,   \n",
       "2  Cetin H, Kose N, Turkmen C, Dulger E, Bilgin S...   \n",
       "3        Stevens AR, Ahmed U, Vigneswara V, Ahmed Z,   \n",
       "4  Giordano V, Alves DD, Paes RP, Amaral AB, Gior...   \n",
       "\n",
       "                                  journal  \\\n",
       "0                               *SICOT-J*   \n",
       "1                  *Turkish neurosurgery*   \n",
       "2                  *Turkish neurosurgery*   \n",
       "3                *Molecular neurobiology*   \n",
       "4  *Journal of experimental orthopaedics*   \n",
       "\n",
       "                                               links  \n",
       "0  * [Radiological, functional, and anatomical ou...  \n",
       "1  * [Application of Individualized 3D-Printed Ar...  \n",
       "2  * [Do Stabilization Exercises Increase the Eff...  \n",
       "3  * [Pigment Epithelium-Derived Factor Promotes ...  \n",
       "4  * [The role of the medial plate for Pauwels ty...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add info for github markdown format\n",
    "papers_df['title']   = [title if title[1] is not '[' else title[1:-1] for title in papers_df['title']]\n",
    "papers_df['authors'] = [authors[k] if authors[k][1] is not '[' else authors[1:-1] for k in indx]\n",
    "papers_df['journal'] = [journals[k] for k in indx]\n",
    "papers_df['links']   = [links[k]    for k in indx]\n",
    "#generate filename\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.csv']\n",
    "fname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate.md']\n",
    "mdname = 'Literature_Updates/'+'-'.join(strings)\n",
    "strings = [str(now.year), str(now.month), str(now.day),'litupdate']\n",
    "urlname = '-'.join(strings)\n",
    "\n",
    "print('Filename: ',fname)\n",
    "\n",
    "# papers_df = papers_df.sort_values(by = ['topic'])\n",
    "# papers_df = papers_df.reset_index(drop = True)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Biomechanical experimental study on brace with stiletto needle therapy for scoliosis]](https://www.ncbi.nlm.nih.gov/pubmed/31027409)\n"
     ]
    }
   ],
   "source": [
    "for item in papers_df['links']:\n",
    "    if 'experimental study' in item:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as .csv "
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Literature Update Exported as .csv\n"
     ]
    }
   ],
   "source": [
    "papers_df.sort_values('topic').to_csv(fname, index = False)\n",
    "print('\\nLiterature Update Exported as .csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile papers grouped by topic"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Biomechanical experimental study on brace with stiletto needle therapy for scoliosis]](https://www.ncbi.nlm.nih.gov/pubmed/31027409)\n",
      "Literature Update Exported as Markdown\n",
      "Location: Literature_Updates/2019-5-5-litupdate.md\n"
     ]
    }
   ],
   "source": [
    "md_file = open(mdname, 'w', encoding = 'utf-8')\n",
    "md_file.write('---\\n')\n",
    "md_file.write('title: Biomechanics Literature Update\\n')\n",
    "md_file.write('collection: literature\\n')\n",
    "md_file.write('permalink: /literature/%s\\n' % urlname)\n",
    "md_file.write('excerpt: <br>\\n')\n",
    "md_file.write('toc: true\\n')\n",
    "md_file.write('toc_sticky: true\\n')\n",
    "md_file.write('toc_label: Topics\\n')\n",
    "md_file.write('---\\n')\n",
    "\n",
    "#tidy up topic strings\n",
    "topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n",
    "ss = [s for s in topic_list if 'UNIQUE' in s]\n",
    "for i,t in enumerate(topic_list):\n",
    "    if 'UNIQUE' in t:  \n",
    "        topic_list[i] = 'UNIQUE TOPIC'\n",
    "    if 'IMPACT' in t:\n",
    "        topic_list[i] = 'TRAUMA/IMPACT'\n",
    "\n",
    "md_file.write('### Created by: [Ryan Alcantara](https://twitter.com/Ryan_Alcantara_) & [Gary Bruening](https://twitter.com/garebearbru) - University of Colorado Boulder\\n\\n')\n",
    "# md_file.write('### Table Of Contents: \\n')\n",
    "# for topic in topic_list:\n",
    "#     md_file.write('[%s](#%s)  \\n' % (topic, str.lower(topic).replace('/','').replace(' ','')))\n",
    "# md_file.write('\\n')\n",
    "for topic in topic_list:\n",
    "    md_file.write('----\\n')\n",
    "    md_file.write('# %s\\n' % topic)\n",
    "    md_file.write('----\\n')\n",
    "    md_file.write('\\n')\n",
    "    md_file.write('[Back to top](#created-by-ryan-alcantara--gary-bruening---university-of-colorado-boulder)')\n",
    "    md_file.write('\\n')\n",
    "    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop = True))\n",
    "    for i,paper in enumerate(papers_subset['links']):\n",
    "        md_file.write('%s\\n' % paper)\n",
    "        md_file.write('%s\\n' % papers_subset['authors'][i])\n",
    "        md_file.write('%s.  \\n' % papers_subset['journal'][i])\n",
    "        md_file.write('\\n')\n",
    "\n",
    "md_file.close()\n",
    "print('Literature Update Exported as Markdown')\n",
    "print('Location:',mdname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
