{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classify_papers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XJG5shp08CGC"},"source":["Uses Fine-Tuned BERT network to classify biomechanics papers from PubMed"]},{"cell_type":"code","metadata":{"id":"6klLdde-78nI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608835590615,"user_tz":420,"elapsed":47562,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"0ea1e408-dd2b-4b50-9180-37cc34057a88"},"source":["# Install & load libraries\n","try:\n","  from official.nlp import optimization\n","except:\n","  !pip install -q -U tf-models-official\n","  from official.nlp import optimization\n","try:\n","  from Bio import Entrez\n","except:\n","  !pip install -q -U biopython\n","  from Bio import Entrez\n","try:\n","  import tensorflow_text as text\n","except:\n","  !pip install -q -U tensorflow_text\n","  import tensorflow_text as text\n","\n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import tensorflow as tf\n","import string\n","import datetime\n","from bs4 import BeautifulSoup\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import load_model\n","import tensorflow_hub as hub\n","from google.colab import drive\n","import datetime as dt\n","today = dt.date.today()\n","yesterday = today - dt.timedelta(days=1)\n","week_ago = yesterday - dt.timedelta(days=7)  # week ago yesterday\n","# Mount Google Drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 849kB 20.0MB/s \n","\u001b[K     |████████████████████████████████| 36.7MB 83kB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 53.8MB/s \n","\u001b[K     |████████████████████████████████| 102kB 12.3MB/s \n","\u001b[K     |████████████████████████████████| 174kB 53.8MB/s \n","\u001b[K     |████████████████████████████████| 358kB 54.8MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 2.3MB 12.8MB/s \n","\u001b[K     |████████████████████████████████| 3.4MB 14.3MB/s \n","\u001b[?25h[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaSczx4IuQ0Y","executionInfo":{"status":"ok","timestamp":1608835635862,"user_tz":420,"elapsed":34952,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"c3e23aab-426c-4b33-de49-7856fa137cb0"},"source":["\n","# Define Search Criteria ----\n","def search(query):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.esearch(db='pubmed',\n","                            sort='most recent',\n","                            retmax='5000',\n","                            retmode='xml',\n","                            datetype='pdat',\n","                            # reldate=7,  # only within n days from now\n","                            mindate=min_date,\n","                            maxdate=max_date,  # for searching date range\n","                            term=query)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Perform Search and Pull Paper Titles ----\n","def fetch_details(ids):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.efetch(db='pubmed',\n","                           retmode='xml',\n","                           id=ids)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Make the stop words for string cleaning ----\n","def html_strip(text):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.replace('[','').replace(']','')\n","    return text\n","\n","def clean_str(text, stops):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.split()\n","    return ' '.join([word for word in text if word not in stops])\n","\n","stop = list(stopwords.words('english'))\n","stop_c = [string.capwords(word) for word in stop]\n","for word in stop_c:\n","    stop.append(word)\n","\n","new_stop = ['The', 'An', 'A', 'Do', 'Is', 'In', 'StringElement', \n","            'NlmCategory', 'Label', 'attributes', 'INTRODUCTION',\n","            'METHODS', 'BACKGROUND', 'RESULTS', 'CONCLUSIONS']\n","for s in new_stop:\n","    stop.append(s)\n","\n","# Search terms (can test string with Pubmed Advanced Search) ----\n","# search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')\n","min_date = week_ago.strftime('%m/%d/%Y')\n","max_date = yesterday.strftime('%m/%d/%Y')\n","search_results = search('(biomech*[Title/Abstract] OR locomot*[Title/Abstract] NOT opiod*[Title/Abstract] NOT pharm*[Journal] NOT mice[Title/Abstract] NOT rats[Title/Abstract] NOT elegans[Title/Abstract])')\n","id_list = search_results['IdList']\n","papers = fetch_details(id_list)\n","print(len(papers['PubmedArticle']), 'Papers found')\n","\n","titles, full_titles, keywords, authors, links, journals, abstracts = ([] for i in range(7))\n","\n","for paper in papers['PubmedArticle']:\n","    # clean and store titles, abstracts, and links\n","    t = clean_str(paper['MedlineCitation']['Article']['ArticleTitle'], \n","                  stop).replace('[','').replace(']','').capitalize()  # rm brackets that survived beautifulsoup, sentence case\n","    titles.append(t)\n","    full_titles.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n","    pmid = paper['MedlineCitation']['PMID']\n","    links.append('[URL=\"https://www.ncbi.nlm.nih.gov/pubmed/{0}\"]{1}[/URL]'.format(pmid, html_strip(paper['MedlineCitation']['Article']['ArticleTitle'])))\n","    try:\n","        abstracts.append(clean_str(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0], \n","                                    stop).replace('[','').replace(']','').capitalize())  # rm brackets that survived beautifulsoup, sentence case\n","    except:\n","        abstracts.append('')\n","\n","    # clean and store authors\n","    auths = []\n","    try:\n","        for auth in paper['MedlineCitation']['Article']['AuthorList']:\n","            try:  # see if there is a last name and initials\n","                auth_name = [auth['LastName'], auth['Initials'] + ',']\n","                auth_name = ' '.join(auth_name)\n","                auths.append(auth_name)\n","            except:\n","                if 'LastName' in auth.keys():  # maybe they don't have initials\n","                    auths.append(auth['LastName'] + ',')\n","                else:  # no last name\n","                    auths.append('')\n","                    print(paper['MedlineCitation']['Article']['ArticleTitle'],\n","                          'has an issue with an author name:')\n","\n","    except:\n","        auths.append('AUTHOR NAMES ERROR')\n","        print(paper['MedlineCitation']['Article']['ArticleTitle'], 'has no author list?')\n","    # compile authors\n","    authors.append(' '.join(auths).replace('[','').replace(']',''))  # rm brackets in names\n","    # journal names\n","    journals.append(paper['MedlineCitation']['Article']['Journal']['Title'].replace('[','').replace(']',''))  # rm brackets\n","\n","    # store keywords \n","    if paper['MedlineCitation']['KeywordList'] != []:\n","        kwds = []\n","        for kw in paper['MedlineCitation']['KeywordList'][0]:\n","            kwds.append(kw[:])\n","        keywords.append(', '.join(kwds).lower())\n","    else:\n","      keywords.append('')\n","\n","# Put Titles, Abstracts, Authors, Journal, and Keywords into dataframe\n","papers_df = pd.DataFrame({'title': titles,\n","                          'keywords': keywords,\n","                          'abstract': abstracts,\n","                          'authors': authors,\n","                          'journal': journals,\n","                          'links': links,\n","                          'raw_title': full_titles,\n","                          'mindate': min_date,\n","                          'maxdate': max_date})\n","\n","\n","# remove papers with no title or no authors\n","for index, row in papers_df.iterrows():\n","    if row['title'] == '' or row['authors'] == 'AUTHOR NAMES ERROR':\n","        papers_df.drop(index, inplace=True)\n","papers_df.reset_index(drop=True, inplace=True)\n","\n","# join titles and abstract\n","papers_df['BERT_input'] = pd.DataFrame(papers_df['title'] + ' ' + papers_df['abstract'])\n","\n","# Load Fine-Tuned BERT Network ----\n","model = tf.saved_model.load('/content/gdrive/My Drive/literature_update/Data/BiomchBERT/')\n","print('Loaded model from disk')\n","\n","# Load Label Encoder ----\n","le = LabelEncoder()\n","le.classes_ = np.load('/content/gdrive/My Drive/literature_update/Data/BERT_label_encoder.npy')\n","print('Loaded Label Encoder')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["81 Papers found\n","[Current treatment standard for patella fractures in Germany]. has an issue with an author name:\n","Loaded model from disk\n","Loaded Label Encoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55tVgCM--ktr"},"source":["# Predict Paper Topic ----\n","predicted_topic = model(papers_df['BERT_input'], training=False)  # will run out of GPU memory (14GB) if predicting more than ~2000 title+abstracts at once"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QvD9JQj7-2_e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608836117234,"user_tz":420,"elapsed":1117,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"ade1c947-4dc4-414a-c896-0d7d728e0e98"},"source":["# Determine Publications that BiomchBERT is unsure about ----\n","topics, pred_val_str = ([] for i in range(2))\n","\n","for pred_prob in predicted_topic:\n","    pred_val = np.max(pred_prob)\n","    if pred_val > 1.5 * np.sort(pred_prob)[-2]:  # Is top confidence score more than 1.5x the second best confidence score?\n","        topics.append(le.inverse_transform([np.argmax(pred_prob)])[0])\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        # pred_val_str.append(pred_val * 100)  # just report top category\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))  # report top 2 categories\n","    else:\n","        topics.append('UNKNOWN')\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))\n","        \n","papers_df['topic'] = topics\n","papers_df['pred_val'] = pred_val_str\n","\n","print('BiomchBERT is unsure about {0} papers\\n'.format(len(papers_df[papers_df['topic'] == 'UNKNOWN'])))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BiomchBERT is unsure about 10 papers\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeacO2b3WHFu","executionInfo":{"status":"ok","timestamp":1608836266800,"user_tz":420,"elapsed":83569,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"11b18e61-6d02-43c9-db75-ae9265c1370a"},"source":["# Prompt User to decide for BiomchBERT ----\n","unknown_papers = papers_df[papers_df['topic'] == 'UNKNOWN']\n","for indx, paper in unknown_papers.iterrows():\n","  print(paper['raw_title'])\n","  print(paper['journal'])\n","  print(paper['pred_val'])\n","  print()\n","  options = []\n","  for cls in le.classes_:\n","    if cls in paper['pred_val']:\n","      options.append(cls)\n","  choice = input('(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? ')\n","  print()\n","  if choice == '1':\n","    papers_df.iloc[indx]['topic'] = options[0]\n","  elif choice == '2':\n","    papers_df.iloc[indx]['topic'] = options[1]\n","  elif choice == 'o':\n","    # print all categories so you can select\n","    for i in zip(range(len(le.classes_)),le.classes_):\n","      print(i)  \n","    new_cat = input('Enter number of new class or type \"r\" to remove paper: ')\n","    print()\n","    if new_cat == 'r':\n","      papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","    else:\n","      papers_df.iloc[indx]['topic'] = le.classes_[int(new_cat)] \n","  elif choice == 'r':\n","    papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","\n","print('Removing {0} papers\\n'.format(len(papers_df[papers_df['topic'] == '_REMOVE_'])))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Comparison of Screw Quantity and Placement of Metacarpal Fracture Fixation: A Biomechanical Study.\n","Hand (New York, N.Y.)\n","52.7% HAND/FINGER/FOOT/TOE; 40.8% ORTHOPAEDICS/SURGERY\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Biomechanical evaluation of the stability of extra-articular distal radius fractures fixed with volar locking plates according to the length of the distal locking screw.\n","Computer methods in biomechanics and biomedical engineering\n","50.7% ORTHOPAEDICS/SURGERY; 44.5% HAND/FINGER/FOOT/TOE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Non-banked curved tracks influence movement symmetry in two-year-old Standardbred trotters.\n","Equine veterinary journal\n","53.3% VETERINARY/AGRICULTURAL; 43.4% COMPARATIVE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Neurodevelopmental outcome of healthy term newborn with serum bilirubin >15 mg/dl at one year.\n","Journal of neonatal-perinatal medicine\n","18.1% REHABILITATION; 13.8% NEURAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Mathematical model of the auditory nerve response to stimulation by a micro-machined cochlea.\n","International journal for numerical methods in biomedical engineering\n","31.5% VISUAL/VESTIBULAR; 23.7% MODELING\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Gesture-speech physics in fluent speech and rhythmic upper limb movements.\n","Annals of the New York Academy of Sciences\n","16.4% NEURAL; 15.8% COMPARATIVE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 9\n","\n","Correction: The effects of locomotor activity on gastrointestinal symptoms of irritable bowel syndrome among younger people: An observational study.\n","PloS one\n","26.5% ERGONOMICS; 19.6% MUSCLE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Timing precision in fly flight control: integrating mechanosensory input with muscle physiology.\n","Proceedings. Biological sciences\n","42.7% COMPARATIVE; 36.1% NEURAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Updating headings in 3D navigation.\n","Quarterly journal of experimental psychology (2006)\n","37.7% VISUAL/VESTIBULAR; 26.4% GAIT/LOCOMOTION\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Hydrodynamic interactions in squirmer dumbbells: active stress-induced alignment and locomotion.\n","Soft matter\n","36.1% MODELING; 31.3% CELLULAR/SUBCELLULAR\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Removing 3 papers\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Deqf5q7BdTAJ"},"source":["# Double check that none of these papers were included in past literature updates ----\n","# load prior papers\n","# papers_df.to_csv('/content/gdrive/My Drive/literature_update/Updates/prior_papers.csv', index=False)  # run ONLY if there are no prior papers\n","prior_papers = pd.read_csv('/content/gdrive/My Drive/literature_update/Updates/prior_papers.csv')\n","prior_papers.dropna(subset=['title'], inplace=True)\n","prior_papers.reset_index(drop=True, inplace=True)\n","\n","# find matching titles between current week and prior papers\n","match = papers_df['title'].isin(prior_papers['title'])  # boolean\n","\n","# filter and check if everything accidentally was removed\n","filtered_papers_df = papers_df.drop(papers_df[match].index)\n","if filtered_papers_df.shape[0] < 1:\n","    raise ValueError('might have removed all the papers for some reason. ')\n","else:\n","    papers_df = filtered_papers_df\n","    papers_df.reset_index(drop=True, inplace=True)\n","    updated_prior_papers = pd.concat([prior_papers, papers_df], axis=0)\n","    updated_prior_papers.reset_index(drop=True, inplace=True)\n","    updated_prior_papers.to_csv('/content/gdrive/My Drive/literature_update/Updates/prior_papers.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fQKyxoBF36B","executionInfo":{"status":"ok","timestamp":1608835983428,"user_tz":420,"elapsed":513,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"786d130e-584b-4cd0-f428-d150a8d57e45"},"source":["# Create Text File for Biomch-L ----\n","# Compile papers grouped by topic\n","txtname = '/content/gdrive/My Drive/literature_update/Updates/' + today.strftime(\"%Y-%m-%d\") + '-litupdate.txt'\n","txt = open(txtname, 'w', encoding='utf-8')\n","txt.write('[SIZE=16px][B]LITERATURE UPDATE[/B][/SIZE]\\n')\n","txt.write(week_ago.strftime(\"%b %d\") + ' - '+ yesterday.strftime(\"%b %d, %Y\")+'\\n')  # a week ago from yesterday.\n","txt.write(\n","    \"\"\"\n","Literature search terms: biomech* & locomot*\n","\n","Publications are classified by [URL=\"https://www.github.com/alcantarar/BiomchBERT\"]BiomchBERT[/URL], a neural network trained on past Biomch-L Literature Updates. BiomchBERT is managed by [URL=\"https://www.ryan-alcantara.com\"]Ryan Alcantara[/URL], a PhD Candidate at the University of Colorado Boulder. Each publication has a score (out of 100%) reflecting how confident BiomchBERT is that the publication belongs in a particular category (top 2 shown). If something doesn't look right, [URL=\"https://www.github.com/alcantarar/BiomchBERT/issues/new\"]submit an issue[/URL].\n","\n","[URL=\"https://www.twitter.com/Ryan_Alcantara_\"]Twitter: @Ryan_Alcantara_[/URL]. \n","\n","*********************NOTE*********************\n","- Not all articles have a DOI.\n","- Some DOI links may not yet be available online.\n","- Articles with no volume, issue or page numbers indicate that the article has not been published in paper form yet, but may be available in electronic form through the publisher\n","\n","\n","    \"\"\"\n","    )\n","\n","# Write papers to text file grouped by topic ----\n","topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n","\n","for topic in topic_list:\n","    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop=True))\n","    txt.write('\\n')\n","    # TOPIC NAME (with some cleaning)\n","    if topic == '_REMOVE_':\n","      continue\n","    elif topic == 'UNKNOWN':\n","        txt.write('[SIZE=16px][B]*Papers BiomchBERT is unsure how to classify*[/B][/SIZE]\\n')\n","    elif topic == 'CARDIOVASCULAR/CARDIOPULMONARY':\n","      topic = 'CARDIOVASCULAR/PULMONARY'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'CELLULAR/SUBCELLULAR':\n","      topic = 'CELLULAR'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SURGERY':\n","      topic = 'ORTHOPAEDICS (SURGERY)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SPINE':\n","      topic = 'ORTHOPAEDICS (SPINE)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    else:\n","        txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    # HYPERLINKED PAPERS, AUTHORS, JOURNAL NAME\n","    for i, paper in enumerate(papers_subset['links']):\n","        txt.write('[B]%s[/B] ' % paper)\n","        txt.write('%s ' % papers_subset['authors'][i])\n","        txt.write('[I]%s[/I]. ' % papers_subset['journal'][i])\n","        # CONFIDENCE SCORE (BERT softmax categorical crossentropy)\n","        try:\n","            txt.write('(%.1f%%) \\n\\n' % papers_subset['pred_val'][i])\n","        except:\n","            txt.write('(%s)\\n\\n' % papers_subset['pred_val'][i]) \n","\n","txt.close()\n","print('Literature Update Exported for Biomch-L')\n","print('Location:', txtname)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Literature Update Exported for Biomch-L\n","Location: /content/gdrive/My Drive/literature_update/Updates/2020-12-24-litupdate.txt\n"],"name":"stdout"}]}]}