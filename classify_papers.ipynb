{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classify_papers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XJG5shp08CGC"},"source":["Uses Fine-Tuned BERT network to classify biomechanics papers from PubMed"]},{"cell_type":"code","metadata":{"id":"6klLdde-78nI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608765453962,"user_tz":420,"elapsed":55106,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"01392d0e-4dad-457d-ea47-1e2b375cee96"},"source":["# Install & load libraries\n","try:\n","  from official.nlp import optimization\n","except:\n","  !pip install -q -U tf-models-official\n","  from official.nlp import optimization\n","try:\n","  from Bio import Entrez\n","except:\n","  !pip install -q -U biopython\n","  from Bio import Entrez\n","try:\n","  import tensorflow_text as text\n","except:\n","  !pip install -q -U tensorflow_text\n","  import tensorflow_text as text\n","\n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import tensorflow as tf\n","import string\n","import datetime\n","from bs4 import BeautifulSoup\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import load_model\n","import tensorflow_hub as hub\n","from google.colab import drive\n","import datetime as dt\n","today = dt.date.today()\n","yesterday = today - dt.timedelta(days=1)\n","week_ago = yesterday - dt.timedelta(days=7)  # week ago yesterday\n","# Mount Google Drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 849kB 11.1MB/s \n","\u001b[K     |████████████████████████████████| 174kB 49.3MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 31.2MB/s \n","\u001b[K     |████████████████████████████████| 358kB 39.9MB/s \n","\u001b[K     |████████████████████████████████| 102kB 9.4MB/s \n","\u001b[K     |████████████████████████████████| 36.7MB 134kB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 2.3MB 13.0MB/s \n","\u001b[K     |████████████████████████████████| 3.4MB 12.7MB/s \n","\u001b[?25h[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaSczx4IuQ0Y","executionInfo":{"status":"ok","timestamp":1608765512282,"user_tz":420,"elapsed":56976,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"e95fccc2-1dfe-45fe-94ab-851ed50914d1"},"source":["\n","# Define Search Criteria ----\n","def search(query):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.esearch(db='pubmed',\n","                            sort='most recent',\n","                            retmax='5000',\n","                            retmode='xml',\n","                            datetype='pdat',\n","                            # reldate=7,  # only within n days from now\n","                            mindate=min_date,\n","                            maxdate=max_date,  # for searching date range\n","                            term=query)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Perform Search and Pull Paper Titles ----\n","def fetch_details(ids):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.efetch(db='pubmed',\n","                           retmode='xml',\n","                           id=ids)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Make the stop words for string cleaning ----\n","def html_strip(text):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.replace('[','').replace(']','')\n","    return text\n","\n","def clean_str(text, stops):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.split()\n","    return ' '.join([word for word in text if word not in stops])\n","\n","stop = list(stopwords.words('english'))\n","stop_c = [string.capwords(word) for word in stop]\n","for word in stop_c:\n","    stop.append(word)\n","\n","new_stop = ['The', 'An', 'A', 'Do', 'Is', 'In', 'StringElement', \n","            'NlmCategory', 'Label', 'attributes', 'INTRODUCTION',\n","            'METHODS', 'BACKGROUND', 'RESULTS', 'CONCLUSIONS']\n","for s in new_stop:\n","    stop.append(s)\n","\n","# Search terms (can test string with Pubmed Advanced Search) ----\n","# search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')\n","min_date = week_ago.strftime('%m/%d/%Y')\n","max_date = yesterday.strftime('%m/%d/%Y')\n","search_results = search('(biomech*[Title/Abstract] OR locomot*[Title/Abstract] NOT opiod*[Title/Abstract] NOT pharm*[Journal] NOT mice[Title/Abstract] NOT rats[Title/Abstract] NOT elegans[Title/Abstract])')\n","id_list = search_results['IdList']\n","papers = fetch_details(id_list)\n","print(len(papers['PubmedArticle']), 'Papers found')\n","\n","titles, full_titles, keywords, authors, links, journals, abstracts = ([] for i in range(7))\n","\n","for paper in papers['PubmedArticle']:\n","    # clean and store titles, abstracts, and links\n","    t = clean_str(paper['MedlineCitation']['Article']['ArticleTitle'], \n","                  stop).replace('[','').replace(']','').capitalize()  # rm brackets that survived beautifulsoup, sentence case\n","    titles.append(t)\n","    full_titles.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n","    pmid = paper['MedlineCitation']['PMID']\n","    links.append('[URL=\"https://www.ncbi.nlm.nih.gov/pubmed/{0}\"]{1}[/URL]'.format(pmid, html_strip(paper['MedlineCitation']['Article']['ArticleTitle'])))\n","    try:\n","        abstracts.append(clean_str(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0], \n","                                    stop).replace('[','').replace(']','').capitalize())  # rm brackets that survived beautifulsoup, sentence case\n","    except:\n","        abstracts.append('')\n","\n","    # clean and store authors\n","    auths = []\n","    try:\n","        for auth in paper['MedlineCitation']['Article']['AuthorList']:\n","            try:  # see if there is a last name and initials\n","                auth_name = [auth['LastName'], auth['Initials'] + ',']\n","                auth_name = ' '.join(auth_name)\n","                auths.append(auth_name)\n","            except:\n","                if 'LastName' in auth.keys():  # maybe they don't have initials\n","                    auths.append(auth['LastName'] + ',')\n","                else:  # no last name\n","                    auths.append('')\n","                    print(paper['MedlineCitation']['Article']['ArticleTitle'],\n","                          'has an issue with an author name:')\n","\n","    except:\n","        auths.append('AUTHOR NAMES ERROR')\n","        print(paper['MedlineCitation']['Article']['ArticleTitle'], 'has no author list?')\n","    # compile authors\n","    authors.append(' '.join(auths).replace('[','').replace(']',''))  # rm brackets in names\n","    # journal names\n","    journals.append(paper['MedlineCitation']['Article']['Journal']['Title'].replace('[','').replace(']',''))  # rm brackets\n","\n","    # store keywords \n","    if paper['MedlineCitation']['KeywordList'] != []:\n","        kwds = []\n","        for kw in paper['MedlineCitation']['KeywordList'][0]:\n","            kwds.append(kw[:])\n","        keywords.append(', '.join(kwds).lower())\n","    else:\n","      keywords.append('')\n","\n","# Put Titles, Abstracts, Authors, Journal, and Keywords into dataframe\n","papers_df = pd.DataFrame({'title': titles,\n","                          'keywords': keywords,\n","                          'abstract': abstracts,\n","                          'authors': authors,\n","                          'journal': journals,\n","                          'links': links,\n","                          'raw_title': full_titles,\n","                          'mindate': min_date,\n","                          'maxdate': max_date})\n","\n","\n","# remove papers with no title or no authors\n","for index, row in papers_df.iterrows():\n","    if row['title'] == '' or row['authors'] == 'AUTHOR NAMES ERROR':\n","        papers_df.drop(index, inplace=True)\n","papers_df.reset_index(drop=True, inplace=True)\n","\n","# join titles and abstract\n","papers_df['BERT_input'] = pd.DataFrame(papers_df['title'] + ' ' + papers_df['abstract'])\n","\n","# Load Fine-Tuned BERT Network ----\n","model = tf.saved_model.load('/content/gdrive/My Drive/literature_update/Data/BiomchBERT/')\n","print('Loaded model from disk')\n","\n","# Load Label Encoder ----\n","le = LabelEncoder()\n","le.classes_ = np.load('/content/gdrive/My Drive/literature_update/Data/BERT_label_encoder.npy')\n","print('Loaded Label Encoder')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["104 Papers found\n","[Current treatment standard for patella fractures in Germany]. has an issue with an author name:\n","Loaded model from disk\n","Loaded Label Encoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55tVgCM--ktr","executionInfo":{"status":"ok","timestamp":1608765866915,"user_tz":420,"elapsed":41128,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}}},"source":["# Predict Paper Topic ----\n","predicted_topic = model(papers_df['BERT_input'], training=False)  # will run out of GPU memory (14GB) if predicting more than ~2000 title+abstracts at once"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"QvD9JQj7-2_e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608765871900,"user_tz":420,"elapsed":1225,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"649a7bed-c649-4198-dc3a-b87b7bfd9aba"},"source":["# Determine Publications that BiomchBERT is unsure about ----\n","topics, pred_val_str = ([] for i in range(2))\n","\n","for pred_prob in predicted_topic:\n","    pred_val = np.max(pred_prob)\n","    if pred_val > 1.5 * np.sort(pred_prob)[-2]:  # Is top confidence score more than 1.5x the second best confidence score?\n","        topics.append(le.inverse_transform([np.argmax(pred_prob)])[0])\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        # pred_val_str.append(pred_val * 100)  # just report top category\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))  # report top 2 categories\n","    else:\n","        topics.append('UNKNOWN')\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))\n","        \n","papers_df['topic'] = topics\n","papers_df['pred_val'] = pred_val_str\n","\n","print('BiomchBERT is unsure about {0} papers\\n'.format(len(papers_df[papers_df['topic'] == 'UNKNOWN'])))\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["BiomchBERT is unsure about 12 papers\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeacO2b3WHFu","executionInfo":{"status":"ok","timestamp":1608766092094,"user_tz":420,"elapsed":58805,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"5aa1e913-5d68-4b44-c3ab-312a762c75f2"},"source":["# Prompt User to decide for BiomchBERT ----\n","unknown_papers = papers_df[papers_df['topic'] == 'UNKNOWN']\n","for indx, paper in unknown_papers.iterrows():\n","  print(paper['raw_title'])\n","  print(paper['journal'])\n","  print(paper['pred_val'])\n","  print()\n","  options = []\n","  for cls in le.classes_:\n","    if cls in paper['pred_val']:\n","      options.append(cls)\n","  choice = input('(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? ')\n","  print()\n","  if choice == '1':\n","    papers_df.iloc[indx]['topic'] = options[0]\n","  elif choice == '2':\n","    papers_df.iloc[indx]['topic'] = options[1]\n","  elif choice == 'o':\n","    # print all categories so you can select\n","    for i in zip(range(len(le.classes_)),le.classes_):\n","      print(i)\n","    new_cat = input('Enter number of new class or type \"r\" to remove paper: ')\n","    if new_cat == 'r':\n","      papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","    else:\n","      papers_df.iloc[indx]['topic'] = le.classes_[int(new_cat)] \n","  elif choice == 'r':\n","    papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","\n","print('Removing {0} papers\\n'.format(len(papers_df[papers_df['topic'] == '_REMOVE_'])))\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Employment status as a major determinant for lower physical activity of patients with epilepsy: A case-control study.\n","Epilepsy & behavior : E&B\n","25.8% ERGONOMICS; 23.1% REHABILITATION\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 19\n","Exploring Correlates of Preschool-Aged Children's Locomotor Skills: Individual and Parent Demographics and Home Environment.\n","Perceptual and motor skills\n","46.8% GAIT/LOCOMOTION; 34.2% SPORT/EXERCISE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: r\n","Neurodevelopmental outcome of healthy term newborn with serum bilirubin >15 mg/dl at one year.\n","Journal of neonatal-perinatal medicine\n","15.5% CARDIOVASCULAR/CARDIOPULMONARY; 12.0% TISSUE/BIOMATERIAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Mathematical model of the auditory nerve response to stimulation by a micro-machined cochlea.\n","International journal for numerical methods in biomedical engineering\n","46.5% MODELING; 33.2% VISUAL/VESTIBULAR\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","The Relationship between Locomotive Syndrome Risk, Gait Pattern, and Standing Posture in Young Japanese Women: A Cross-Sectional Study.\n","Healthcare (Basel, Switzerland)\n","54.5% POSTURE/BALANCE; 39.0% GAIT/LOCOMOTION\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Electromyographic Profile of the Shoulder During Stability Exercises With Kettlebells.\n","Journal of sport rehabilitation\n","42.6% REHABILITATION; 33.8% ERGONOMICS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Correction: The effects of locomotor activity on gastrointestinal symptoms of irritable bowel syndrome among younger people: An observational study.\n","PloS one\n","43.0% GAIT/LOCOMOTION; 31.8% METHODS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Timing precision in fly flight control: integrating mechanosensory input with muscle physiology.\n","Proceedings. Biological sciences\n","38.8% COMPARATIVE; 33.4% NEURAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Lysine-Arginine Advanced Glycation End-Product Cross-links and the Effect on Collagen Structure: A Molecular Dynamics Study.\n","Proteins\n","46.5% CELLULAR/SUBCELLULAR; 33.5% TISSUE/BIOMATERIAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Multimodal control of neck muscles for vestibular mediated head oscillation damping during walking: a pilot study.\n","European archives of oto-rhino-laryngology : official journal of the European Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the German Society for Oto-Rhino-Laryngology - Head and Neck Surgery\n","41.8% VISUAL/VESTIBULAR; 29.9% GAIT/LOCOMOTION\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Thermal acclimation leads to variable muscle responses in two temperate labrid fishes.\n","The Journal of experimental biology\n","53.5% MUSCLE; 45.1% COMPARATIVE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Removing 10 papers\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8VfSwelY7Sux","executionInfo":{"status":"ok","timestamp":1608766097642,"user_tz":420,"elapsed":779,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"ccdcef6a-91b8-4e21-c006-9b7b0b8c32be"},"source":[""],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'REHABILITATION'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"Deqf5q7BdTAJ","executionInfo":{"status":"ok","timestamp":1608749403866,"user_tz":420,"elapsed":324,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}}},"source":["# Double check that none of these papers were included in past literature updates ----\n","# load prior papers\n","# papers_df.to_csv('/content/gdrive/My Drive/literature_update/Updates/prior_papers.csv', index=False)  # run ONLY if there are no prior papers\n","prior_papers = pd.read_csv('/content/gdrive/My Drive/literature_update/Updates/prior_papers.csv')\n","prior_papers.dropna(subset=['title'], inplace=True)\n","prior_papers.reset_index(drop=True, inplace=True)\n","\n","# find matching titles between current week and prior papers\n","match = papers_df['title'].isin(prior_papers['title'])  # boolean\n","\n","# filter and check if everything accidentally was removed\n","filtered_papers_df = papers_df.drop(papers_df[match].index)\n","if filtered_papers_df.shape[0] < 1:\n","    raise ValueError('might have removed all the papers for some reason. ')\n","else:\n","    papers_df = filtered_papers_df\n","    papers_df.reset_index(drop=True, inplace=True)\n","    updated_prior_papers = pd.concat([prior_papers, papers_df], axis=0)\n","    updated_prior_papers.reset_index(drop=True, inplace=True)\n","    updated_prior_papers.to_csv('/content/gdrive/My Drive/literature_update/Updates/prior_papers.csv', index=False)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fQKyxoBF36B","executionInfo":{"status":"ok","timestamp":1608766107505,"user_tz":420,"elapsed":1545,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"23f102ba-af40-4ef4-f9db-666b17a88a01"},"source":["# Create Text File for Biomch-L ----\n","# Compile papers grouped by topic\n","txtname = '/content/gdrive/My Drive/literature_update/Updates/' + today.strftime(\"%Y-%m-%d\") + '-litupdate.txt'\n","txt = open(txtname, 'w', encoding='utf-8')\n","txt.write('[SIZE=16px][B]LITERATURE UPDATE[/B][/SIZE]\\n')\n","txt.write(week_ago.strftime(\"%b %d\") + ' - '+ yesterday.strftime(\"%b %d, %Y\")+'\\n')  # a week ago from yesterday.\n","txt.write(\n","    \"\"\"\n","Literature search terms: biomech* & locomot*\n","\n","Publications are classified by [URL=\"https://www.github.com/alcantarar/literature_update\"]BiomchBERT[/URL], a neural network trained on past Biomch-L Literature Updates. BiomchBERT is managed by [URL=\"https://www.twitter.com/Ryan_Alcantara_\"]Ryan Alcantara[/URL], a PhD Candidate at the University of Colorado Boulder. Each publication has a score (out of 100%) reflecting how confident BiomchBERT is that the publication belongs in a particular category (top 2 shown). If something doesn't look right, [URL=\"https://www.github.com/alcantarar/literature_update/issues/new\"]submit an issue[/URL].\n","\n","[URL=\"https://www.ryan-alcantara.com\"]www.ryan-alcantara.com[/URL]. \n","\n","*********************NOTE*********************\n","- Not all articles have a DOI.\n","- Some DOI links may not yet be available online.\n","- Articles with no volume, issue or page numbers indicate that the article has not been published in paper form yet, but may be available in electronic form through the publisher\n","\n","\n","    \"\"\"\n","    )\n","\n","# Write papers to text file grouped by topic ----\n","topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n","\n","for topic in topic_list:\n","    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop=True))\n","    txt.write('\\n')\n","    # TOPIC NAME (with some cleaning)\n","    if topic == '_REMOVE_':\n","      continue\n","    elif topic == 'UNKNOWN':\n","        txt.write('[SIZE=16px][B]*Papers BiomchBERT is unsure how to classify*[/B][/SIZE]\\n')\n","    elif topic == 'CARDIOVASCULAR/CARDIOPULMONARY':\n","      topic = 'CARDIOVASCULAR/PULMONARY'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'CELLULAR/SUBCELLULAR':\n","      topic = 'CELLULAR'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SURGERY':\n","      topic = 'ORTHOPAEDICS (SURGERY)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SPINE':\n","      topic = 'ORTHOPAEDICS (SPINE)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    else:\n","        txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    # HYPERLINKED PAPERS, AUTHORS, JOURNAL NAME\n","    for i, paper in enumerate(papers_subset['links']):\n","        txt.write('[B]%s[/B] ' % paper)\n","        txt.write('%s ' % papers_subset['authors'][i])\n","        txt.write('[I]%s[/I]. ' % papers_subset['journal'][i])\n","        # CONFIDENCE SCORE (BERT softmax categorical crossentropy)\n","        try:\n","            txt.write('(%.1f%%) \\n\\n' % papers_subset['pred_val'][i])\n","        except:\n","            txt.write('(%s)\\n\\n' % papers_subset['pred_val'][i]) \n","\n","txt.close()\n","print('Literature Update Exported for Biomch-L')\n","print('Location:', txtname)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Literature Update Exported for Biomch-L\n","Location: /content/gdrive/My Drive/literature_update/Updates/2020-12-23-litupdate.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JJ8D_5TelB_7"},"source":[""],"execution_count":null,"outputs":[]}]}